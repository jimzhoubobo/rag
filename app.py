import streamlit as st
import os
from dotenv import load_dotenv
from rag.rag_core import load_vector_store_with_cache, get_qa_chain, get_answer
from etl.document_processor import load_and_process_documents
from constant.constants import ProjectConstants
import tempfile
from log.logger import logger
# åŠ è½½ç¯å¢ƒå˜é‡ å…¥å£
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸­åŒ»ç†ç–—æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸŒ¿",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("ä¸­åŒ»ç†ç–—æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

# ä¾§è¾¹æ 
st.sidebar.header("é…ç½®é€‰é¡¹")

# æ–‡ä»¶ä¸Šä¼ å™¨
uploaded_files = st.sidebar.file_uploader(
    "ä¸Šä¼ é¢å¤–çš„PDFæˆ–TXTæ–‡ä»¶",
    type=["pdf", "txt"],
    accept_multiple_files=True
)

# æ£€ç´¢æ•°é‡æ»‘åŠ¨æ¡
top_k = st.sidebar.slider("æ£€ç´¢æ–‡æ¡£æ•°é‡", 1, 10, 4)

# å®‰å…¨å…è´£å£°æ˜
st.sidebar.markdown("""
---
### âš ï¸ å®‰å…¨å…è´£å£°æ˜
æœ¬ç³»ç»Ÿæä¾›çš„æ‰€æœ‰ä¿¡æ¯ä»…ä¾›å­¦ä¹ å’Œå‚è€ƒä¹‹ç”¨ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—å»ºè®®ã€‚
å¦‚æœ‰å®é™…å¥åº·é—®é¢˜ï¼Œè¯·åŠ¡å¿…å’¨è¯¢åˆæ ¼çš„ä¸­åŒ»å¸ˆæˆ–å…¶ä»–åŒ»ç–—ä¸“ä¸šäººå£«ã€‚
æœ¬ç³»ç»Ÿä¸å¯¹å› ä½¿ç”¨æˆ–ä¸æ­£ç¡®ä½¿ç”¨æœ¬ç³»ç»Ÿæä¾›çš„ä¿¡æ¯è€Œå¯¼è‡´çš„ä»»ä½•åæœè´Ÿè´£ã€‚
""")

# æ·»åŠ è°ƒè¯•å¼€å…³
debug_mode = st.sidebar.checkbox("è°ƒè¯•æ¨¡å¼")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'qa_chain' not in st.session_state:
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ..."):
        # åˆ›å»ºç©ºçš„æ–‡æ¡£åˆ—è¡¨
        documents = []
        
        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        if uploaded_files:
            temp_dir = tempfile.mkdtemp()
            for uploaded_file in uploaded_files:
                file_path = os.path.join(temp_dir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
            
            # åŠ è½½ä¸Šä¼ çš„æ–‡æ¡£
            uploaded_documents = load_and_process_documents(temp_dir)
            documents.extend(uploaded_documents)
        
        # ç›´æ¥åŠ è½½å·²å­˜åœ¨çš„å‘é‡åº“ï¼Œä¸é‡æ–°å¤„ç†æ–‡æ¡£ç›®å½•ä¸­çš„æ–‡ä»¶
        logger.info("æ­£åœ¨åŠ è½½å‘é‡åº“...")
            
        vector_store = load_vector_store_with_cache(documents, ProjectConstants.get_chroma_db_path())
        
        # åˆ›å»ºQAé“¾
        logger.info("æ­£åœ¨åˆ›å»ºé—®ç­”é“¾...")
            
        st.session_state.qa_chain = get_qa_chain(vector_store, top_k)
        
        logger.info("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")

# ä¸»ç•Œé¢ - é—®é¢˜è¾“å…¥
question = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

# å¤„ç†é—®é¢˜å’Œæ˜¾ç¤ºç­”æ¡ˆ
if question:
    with st.spinner("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."):
        logger.info(f"æ”¶åˆ°é—®é¢˜: {question}")
            
        result = get_answer(question, st.session_state.qa_chain, top_k)
        
        logger.info("ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        
        # æ˜¾ç¤ºé—®é¢˜
        st.subheader("é—®é¢˜")
        st.write(question)
        
        # æ˜¾ç¤ºç­”æ¡ˆ
        st.subheader("ç­”æ¡ˆ")
        st.markdown(result["result"])
        
        # æ˜¾ç¤ºå‚è€ƒèµ„æ–™
        with st.expander("å‚è€ƒèµ„æ–™"):
            for doc in result["source_documents"]:
                st.markdown(f"**æ¥æº**: {doc.metadata.get('source', 'Unknown')}")
                st.markdown(f"**å†…å®¹**: {doc.page_content}")
                st.divider()